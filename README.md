# RestrictedBoltzmannMaschine

# What is this

After completing [Geofrey Hintons Coursera "Neural Networks for Machine Learning" course](https://www.coursera.org/learn/neural-networks) I developed this hoppy application. I implemented the CD1 learning algorithm for Restricted Boltzman Maschines (RBM), stacked 3 RBMs and used them to generate number labels.

# Architecture

![Architecture](.documentation/RBM_architecture.png)

# Result

All followining images had following models:

| Layer  | # Iterations | # Hidden units |
| ------ | ------------ | -------------- |
| Layer1 | 10000        | 200            |
| Layer2 | 2500         | 100            |
| Layer3 | 2500         | 100            |

## Learned weights

### First Layer
![First Layer](.documentation/Weights_in_first_Layer.png)
### Second Layer
![Second Layer](.documentation/Weights_in_second_Layer.png)
### Final Layer
First column represents the visible unit for the hot encoded labels (here not clamped but set to label while training).
![Final Layer](.documentation/Weights_in_final_Layer.png)

## Generated numbers

The number where generated by clamping the 1 hot encoded labels while converging the "RBM 3" with 50000 iterations. Then we use the "Second Layer" activations as Hidden Units activations for a Sigmoid Belief Net with the "RBM 2" and "RBM 1" and "Visible Unit" as downstream layers.
The so generated "Visible Unit" activations are the generated image.

![0 generated](.documentation/Generated_samples_for_0.png)
![1 generated](.documentation/Generated_samples_for_1.png)
![2 generated](.documentation/Generated_samples_for_2.png)
![3 generated](.documentation/Generated_samples_for_3.png)
![4 generated](.documentation/Generated_samples_for_4.png)
![5 generated](.documentation/Generated_samples_for_5.png)
![6 generated](.documentation/Generated_samples_for_6.png)
![7 generated](.documentation/Generated_samples_for_7.png)
![8 generated](.documentation/Generated_samples_for_8.png)
![9 generated](.documentation/Generated_samples_for_9.png)
